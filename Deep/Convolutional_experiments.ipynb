{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo tomado de https://github.com/StrikingLoo/Cats-and-dogs-classifier-tensorflow-CNN/blob/master/Convolutional_experiments.ipynb. El ejemplo ha sido simplificado y adaptado para el curso introduccion de aprendizaje de maquinas de la Maestria en Ingenieria de la Universidad del Magdalena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path_cat = './PetImages\\\\Cat/*'\n",
    "dir_path_dog = './PetImages\\\\Dog/*'\n",
    "IMG_SIZE = (94, 125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixels_from_path(file_path):\n",
    "    im = Image.open(file_path)\n",
    "    im = im.resize(IMG_SIZE)\n",
    "    np_im = np.array(im)\n",
    "    \n",
    "    return np_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12501\n",
      "12501\n"
     ]
    }
   ],
   "source": [
    "cat_file_list = glob.glob(dir_path_cat) #Busca en el directorio dado todas las imagenes que alli se encuentran\n",
    "dog_file_list = glob.glob(dir_path_dog)\n",
    "print(len(cat_file_list))\n",
    "print(len(dog_file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_size = [IMG_SIZE[1], IMG_SIZE[0], 3] \n",
    "\n",
    "def create_set(file_list, nItems):\n",
    "    new_set = []\n",
    "    for im in file_list[:nItems]:\n",
    "       new_item = pixels_from_path(im)\n",
    "       if len(new_item.shape) != 3:\n",
    "            print('Imagen con tamano diferente', im)\n",
    "       else:\n",
    "          new_set.append(new_item)\n",
    "    \n",
    "    return new_set   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading training cat images...\n",
      "Imagen con tamano diferente ./PetImages\\Cat\\10125.jpg\n",
      "Imagen con tamano diferente ./PetImages\\Cat\\10501.jpg\n",
      "Imagen con tamano diferente ./PetImages\\Cat\\10820.jpg\n",
      "Imagen con tamano diferente ./PetImages\\Cat\\11095.jpg\n",
      "Imagen con tamano diferente ./PetImages\\Cat\\11210.jpg\n",
      "Imagen con tamano diferente ./PetImages\\Cat\\11565.jpg\n",
      "loading training dog images...\n",
      "Imagen con tamano diferente ./PetImages\\Dog\\10158.jpg\n",
      "Imagen con tamano diferente ./PetImages\\Dog\\10401.jpg\n",
      "Imagen con tamano diferente ./PetImages\\Dog\\10747.jpg\n",
      "Imagen con tamano diferente ./PetImages\\Dog\\10797.jpg\n",
      "Imagen con tamano diferente ./PetImages\\Dog\\11410.jpg\n",
      "Imagen con tamano diferente ./PetImages\\Dog\\11675.jpg\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_SIZE = 2048\n",
    "\n",
    "print(\"loading training cat images...\")\n",
    "cat_train_set = create_set( cat_file_list, SAMPLE_SIZE)\n",
    "\n",
    "print(\"loading training dog images...\")\n",
    "dog_train_set = create_set(dog_file_list, SAMPLE_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2042\n",
      "2042\n"
     ]
    }
   ],
   "source": [
    "print(len(cat_train_set))\n",
    "print(len(dog_train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagen con tamano diferente ./PetImages\\Cat\\11874.jpg\n",
      "Imagen con tamano diferente ./PetImages\\Cat\\11935.jpg\n",
      "Imagen con tamano diferente ./PetImages\\Cat\\12080.jpg\n",
      "Imagen con tamano diferente ./PetImages\\Dog\\11849.jpg\n",
      "Imagen con tamano diferente ./PetImages\\Dog\\11853.jpg\n"
     ]
    }
   ],
   "source": [
    "TEST_SIZE = 512\n",
    "cat_file_list_test =  cat_file_list[SAMPLE_SIZE+1:]\n",
    "cat_test_set = create_set(cat_file_list_test, TEST_SIZE)\n",
    "\n",
    "dog_file_list_test =  dog_file_list[SAMPLE_SIZE+1:]\n",
    "dog_test_set = create_set(dog_file_list_test, TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "509\n",
      "510\n"
     ]
    }
   ],
   "source": [
    "print(len(cat_test_set))\n",
    "print(len(dog_test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_size(im_list):\n",
    "   valid_size = (IMG_SIZE[1], IMG_SIZE[0], 3) \n",
    "   for im in im_list:\n",
    "       im_shape = im.shape \n",
    "       #if not (np.array(im_shape) == np.array(valid_size)).all():\n",
    "       if not (np.array_equal(np.array(im_shape), np.array(valid_size))):\n",
    "          print('hay una imagen con un tamano:', im_shape)\n",
    "          im_list.remove(im)\n",
    "   return im_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hay una imagen con un tamano: (125, 94, 4)\n",
      "4083\n",
      "1019\n",
      "4083\n",
      "1019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-eca6d32de37c>:8: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  im_list.remove(im)\n"
     ]
    }
   ],
   "source": [
    "cat_train_set = validate_size(cat_train_set)\n",
    "dog_train_set = validate_size(dog_train_set)\n",
    "\n",
    "cat_test_set = validate_size(cat_test_set)\n",
    "dog_test_set = validate_size(dog_test_set)\n",
    "\n",
    "labels_cat_train = np.ones(len(cat_train_set))\n",
    "labels_dog_train = np.zeros(len(dog_train_set))\n",
    "\n",
    "labels_cat_test = np.ones(len(cat_test_set))\n",
    "labels_dog_test = np.zeros(len(dog_test_set))\n",
    "\n",
    "train_set =  cat_train_set  + dog_train_set\n",
    "y_train = np.concatenate((labels_cat_train, labels_dog_train), axis=None)\n",
    " \n",
    "test_set =  cat_test_set  + dog_test_set\n",
    "y_test = np.concatenate((labels_cat_test, labels_dog_test), axis=None)\n",
    "\n",
    "print(len(train_set))\n",
    "print(len(test_set))\n",
    "print(len(y_train))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4083, 125, 94, 3)\n",
      "(1019, 125, 94, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(train_set)\n",
    "X_test = np.array(test_set)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Un MLP normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "img_size = IMG_SIZE\n",
    "\n",
    "total_pixels = img_size[0] *img_size[1] * 3\n",
    "fc_size = 512\n",
    "\n",
    "#Definicion del modelo\n",
    "\n",
    "inputs = keras.Input(shape=(img_size[1], img_size[0],3), name='ani_image') \n",
    "x = layers.Flatten(name = 'flattened_img')(inputs) #turn image to vector.\n",
    "\n",
    "x = layers.Dense(fc_size, activation='relu', name='first_layer')(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid', name='class')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "customAdam = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=customAdam,  # Optimizer\n",
    "              # Loss function to minimize\n",
    "              loss=\"mean_squared_error\",\n",
    "              # List of metrics to monitor\n",
    "              metrics=[\"accuracy\",\"mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Fit model on training data\n",
      "Epoch 1/10\n",
      "128/128 [==============================] - 7s 53ms/step - loss: 0.5000 - accuracy: 0.4999 - mean_squared_error: 0.5000 - val_loss: 0.5005 - val_accuracy: 0.4995 - val_mean_squared_error: 0.5005\n",
      "Epoch 2/10\n",
      "128/128 [==============================] - 7s 52ms/step - loss: 0.4999 - accuracy: 0.5001 - mean_squared_error: 0.4999 - val_loss: 0.5005 - val_accuracy: 0.4995 - val_mean_squared_error: 0.5005\n",
      "Epoch 3/10\n",
      "128/128 [==============================] - 7s 52ms/step - loss: 0.4999 - accuracy: 0.5001 - mean_squared_error: 0.4999 - val_loss: 0.5005 - val_accuracy: 0.4995 - val_mean_squared_error: 0.5005\n",
      "Epoch 4/10\n",
      "128/128 [==============================] - 7s 51ms/step - loss: 0.4999 - accuracy: 0.5001 - mean_squared_error: 0.4999 - val_loss: 0.5005 - val_accuracy: 0.4995 - val_mean_squared_error: 0.5005\n",
      "Epoch 5/10\n",
      "128/128 [==============================] - 7s 51ms/step - loss: 0.4999 - accuracy: 0.5001 - mean_squared_error: 0.4999 - val_loss: 0.5005 - val_accuracy: 0.4995 - val_mean_squared_error: 0.5005\n",
      "Epoch 6/10\n",
      "128/128 [==============================] - 7s 52ms/step - loss: 0.4999 - accuracy: 0.5001 - mean_squared_error: 0.4999 - val_loss: 0.5005 - val_accuracy: 0.4995 - val_mean_squared_error: 0.5005\n",
      "Epoch 7/10\n",
      "128/128 [==============================] - 7s 51ms/step - loss: 0.4999 - accuracy: 0.5001 - mean_squared_error: 0.4999 - val_loss: 0.5005 - val_accuracy: 0.4995 - val_mean_squared_error: 0.5005\n",
      "Epoch 8/10\n",
      "128/128 [==============================] - 7s 52ms/step - loss: 0.4999 - accuracy: 0.5001 - mean_squared_error: 0.4999 - val_loss: 0.5005 - val_accuracy: 0.4995 - val_mean_squared_error: 0.5005\n",
      "Epoch 9/10\n",
      "128/128 [==============================] - 7s 51ms/step - loss: 0.4999 - accuracy: 0.5001 - mean_squared_error: 0.4999 - val_loss: 0.5005 - val_accuracy: 0.4995 - val_mean_squared_error: 0.5005\n",
      "Epoch 10/10\n",
      "128/128 [==============================] - 7s 52ms/step - loss: 0.4999 - accuracy: 0.5001 - mean_squared_error: 0.4999 - val_loss: 0.5005 - val_accuracy: 0.4995 - val_mean_squared_error: 0.5005\n"
     ]
    }
   ],
   "source": [
    "print('# Fit model on training data')\n",
    "\n",
    "history = model.fit(X_train, \n",
    "                    y_train,\n",
    "                    batch_size=32, \n",
    "                    shuffle = True, #important since we loaded cats first, dogs second.\n",
    "                    epochs=10,\n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Convolutional Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_layer_size = 128\n",
    "img_size = IMG_SIZE\n",
    "\n",
    "conv_inputs = keras.Input(shape=(img_size[1], img_size[0],3), name='ani_image')\n",
    "conv_layer = layers.Conv2D(24, kernel_size=3, activation='relu')(conv_inputs)\n",
    "conv_layer = layers.MaxPool2D(pool_size=(2,2))(conv_layer)\n",
    "conv_x = layers.Flatten(name = 'flattened_features')(conv_layer) #turn image to vector.\n",
    "\n",
    "conv_x = layers.Dense(fc_layer_size, activation='relu', name='first_layer')(conv_x)\n",
    "conv_x = layers.Dense(fc_layer_size, activation='relu', name='second_layer')(conv_x)\n",
    "conv_outputs = layers.Dense(1, activation='sigmoid', name='class')(conv_x)\n",
    "\n",
    "conv_model = keras.Model(inputs=conv_inputs, outputs=conv_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "customAdam = keras.optimizers.Adam(lr=1e-6)\n",
    "conv_model.compile(optimizer=customAdam,  # Optimizer\n",
    "              # Loss function to minimize\n",
    "              loss=\"binary_crossentropy\",\n",
    "              # List of metrics to monitor\n",
    "              metrics=[\"accuracy\",\"mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Fit model on training data\n",
      "Epoch 1/10\n",
      "64/64 [==============================] - 8s 118ms/step - loss: 5.3044 - accuracy: 0.5295 - mean_squared_error: 0.4414 - val_loss: 3.4065 - val_accuracy: 0.5653 - val_mean_squared_error: 0.4004\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 8s 122ms/step - loss: 2.9436 - accuracy: 0.5496 - mean_squared_error: 0.4029 - val_loss: 2.5690 - val_accuracy: 0.5692 - val_mean_squared_error: 0.3876\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 8s 119ms/step - loss: 2.3096 - accuracy: 0.5643 - mean_squared_error: 0.3766 - val_loss: 2.3560 - val_accuracy: 0.5604 - val_mean_squared_error: 0.3883\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 8s 123ms/step - loss: 1.9373 - accuracy: 0.5827 - mean_squared_error: 0.3583 - val_loss: 2.1173 - val_accuracy: 0.5496 - val_mean_squared_error: 0.3838\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 8s 121ms/step - loss: 1.6439 - accuracy: 0.5822 - mean_squared_error: 0.3440 - val_loss: 1.9471 - val_accuracy: 0.5564 - val_mean_squared_error: 0.3776\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 8s 123ms/step - loss: 1.4981 - accuracy: 0.5885 - mean_squared_error: 0.3337 - val_loss: 1.8787 - val_accuracy: 0.5545 - val_mean_squared_error: 0.3717\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 8s 119ms/step - loss: 1.3574 - accuracy: 0.6020 - mean_squared_error: 0.3172 - val_loss: 1.7500 - val_accuracy: 0.5604 - val_mean_squared_error: 0.3652\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 8s 122ms/step - loss: 1.2301 - accuracy: 0.6233 - mean_squared_error: 0.2981 - val_loss: 1.7147 - val_accuracy: 0.5613 - val_mean_squared_error: 0.3622\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 8s 120ms/step - loss: 1.1639 - accuracy: 0.6282 - mean_squared_error: 0.2906 - val_loss: 1.6658 - val_accuracy: 0.5741 - val_mean_squared_error: 0.3558\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 8s 121ms/step - loss: 1.0920 - accuracy: 0.6405 - mean_squared_error: 0.2803 - val_loss: 1.6350 - val_accuracy: 0.5731 - val_mean_squared_error: 0.3540\n"
     ]
    }
   ],
   "source": [
    "print('# Fit model on training data')\n",
    "\n",
    "history = conv_model.fit(X_train, \n",
    "                    y_train, #we pass it th labels\n",
    "                    #If the model is taking forever to train, make this bigger\n",
    "                    #If it is taking forever to load for the first epoch, make this smaller\n",
    "                    batch_size=64, \n",
    "                    shuffle = True,\n",
    "                    epochs=10,\n",
    "                    # We pass it validation data to\n",
    "                    # monitor loss and metrics\n",
    "                    # at the end of each epoch\n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bigger Convolutional Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_layer_size = 256\n",
    "img_size = IMG_SIZE\n",
    "\n",
    "conv_inputs = keras.Input(shape=(img_size[1], img_size[0],3), name='ani_image')\n",
    "\n",
    "conv_layer = layers.Conv2D(48, kernel_size=3, activation='relu')(conv_inputs)\n",
    "conv_layer = layers.MaxPool2D(pool_size=(2,2))(conv_layer)\n",
    "\n",
    "conv_layer = layers.Conv2D(48, kernel_size=3, activation='relu')(conv_layer)\n",
    "conv_layer = layers.MaxPool2D(pool_size=(2,2))(conv_layer)\n",
    "\n",
    "conv_x = layers.Flatten(name = 'flattened_features')(conv_layer) #turn image to vector.\n",
    "\n",
    "conv_x = layers.Dense(fc_layer_size, activation='relu', name='first_layer')(conv_x)\n",
    "conv_x = layers.Dense(fc_layer_size, activation='relu', name='second_layer')(conv_x)\n",
    "conv_outputs = layers.Dense(1, activation='sigmoid', name='class')(conv_x)\n",
    "\n",
    "conv_model = keras.Model(inputs=conv_inputs, outputs=conv_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "customAdam = keras.optimizers.Adam(lr=1e-6)\n",
    "conv_model.compile(optimizer=customAdam,  # Optimizer\n",
    "              # Loss function to minimize\n",
    "              loss=\"binary_crossentropy\",\n",
    "              # List of metrics to monitor\n",
    "              metrics=[\"accuracy\",\"mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Fit model on training data\n",
      "Epoch 1/15\n",
      "64/64 [==============================] - 20s 312ms/step - loss: 2.7832 - accuracy: 0.5133 - mean_squared_error: 0.4269 - val_loss: 2.3080 - val_accuracy: 0.5201 - val_mean_squared_error: 0.4103\n",
      "Epoch 2/15\n",
      "64/64 [==============================] - 20s 318ms/step - loss: 1.9395 - accuracy: 0.5471 - mean_squared_error: 0.3821 - val_loss: 1.9177 - val_accuracy: 0.5329 - val_mean_squared_error: 0.3912\n",
      "Epoch 3/15\n",
      "64/64 [==============================] - 20s 316ms/step - loss: 1.6229 - accuracy: 0.5685 - mean_squared_error: 0.3555 - val_loss: 1.7054 - val_accuracy: 0.5319 - val_mean_squared_error: 0.3806\n",
      "Epoch 4/15\n",
      "64/64 [==============================] - 20s 313ms/step - loss: 1.4441 - accuracy: 0.5805 - mean_squared_error: 0.3390 - val_loss: 1.6130 - val_accuracy: 0.5339 - val_mean_squared_error: 0.3718\n",
      "Epoch 5/15\n",
      "64/64 [==============================] - 20s 318ms/step - loss: 1.3245 - accuracy: 0.5942 - mean_squared_error: 0.3237 - val_loss: 1.5306 - val_accuracy: 0.5427 - val_mean_squared_error: 0.3635\n",
      "Epoch 6/15\n",
      "64/64 [==============================] - 20s 314ms/step - loss: 1.2290 - accuracy: 0.6062 - mean_squared_error: 0.3123 - val_loss: 1.4582 - val_accuracy: 0.5525 - val_mean_squared_error: 0.3538\n",
      "Epoch 7/15\n",
      "64/64 [==============================] - 20s 314ms/step - loss: 1.1396 - accuracy: 0.6218 - mean_squared_error: 0.2978 - val_loss: 1.4359 - val_accuracy: 0.5505 - val_mean_squared_error: 0.3527\n",
      "Epoch 8/15\n",
      "64/64 [==============================] - 20s 320ms/step - loss: 1.0779 - accuracy: 0.6216 - mean_squared_error: 0.2896 - val_loss: 1.3711 - val_accuracy: 0.5633 - val_mean_squared_error: 0.3456\n",
      "Epoch 9/15\n",
      "64/64 [==============================] - 20s 317ms/step - loss: 1.0178 - accuracy: 0.6385 - mean_squared_error: 0.2779 - val_loss: 1.3535 - val_accuracy: 0.5790 - val_mean_squared_error: 0.3411\n",
      "Epoch 10/15\n",
      "64/64 [==============================] - 20s 316ms/step - loss: 0.9611 - accuracy: 0.6410 - mean_squared_error: 0.2690 - val_loss: 1.3063 - val_accuracy: 0.5682 - val_mean_squared_error: 0.3369\n",
      "Epoch 11/15\n",
      "64/64 [==============================] - 20s 313ms/step - loss: 0.9159 - accuracy: 0.6559 - mean_squared_error: 0.2595 - val_loss: 1.2790 - val_accuracy: 0.5702 - val_mean_squared_error: 0.3324\n",
      "Epoch 12/15\n",
      "64/64 [==============================] - 20s 317ms/step - loss: 0.8752 - accuracy: 0.6569 - mean_squared_error: 0.2511 - val_loss: 1.2551 - val_accuracy: 0.5711 - val_mean_squared_error: 0.3282\n",
      "Epoch 13/15\n",
      "64/64 [==============================] - 21s 326ms/step - loss: 0.8393 - accuracy: 0.6689 - mean_squared_error: 0.2435 - val_loss: 1.2281 - val_accuracy: 0.5770 - val_mean_squared_error: 0.3244\n",
      "Epoch 14/15\n",
      "64/64 [==============================] - 20s 318ms/step - loss: 0.8014 - accuracy: 0.6733 - mean_squared_error: 0.2353 - val_loss: 1.2137 - val_accuracy: 0.5780 - val_mean_squared_error: 0.3225\n",
      "Epoch 15/15\n",
      "64/64 [==============================] - 20s 316ms/step - loss: 0.7687 - accuracy: 0.6863 - mean_squared_error: 0.2284 - val_loss: 1.1899 - val_accuracy: 0.5800 - val_mean_squared_error: 0.3205\n"
     ]
    }
   ],
   "source": [
    "print('# Fit model on training data')\n",
    "\n",
    "history = conv_model.fit(X_train, \n",
    "                    y_train, \n",
    "                    batch_size=64, \n",
    "                    shuffle = True,\n",
    "                    epochs=15,\n",
    "                    # We pass it validation data to\n",
    "                    # monitor loss and metrics\n",
    "                    # at the end of each epoch\n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bigger Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_layer_size = 256\n",
    "img_size = IMG_SIZE\n",
    "\n",
    "conv_inputs = keras.Input(shape=(img_size[1], img_size[0],3), name='ani_image')\n",
    "conv_layer = layers.Conv2D(128, kernel_size=3, activation='relu')(conv_inputs)\n",
    "conv_layer = layers.MaxPool2D(pool_size=(2,2))(conv_layer)\n",
    "\n",
    "conv_layer = layers.Conv2D(128, kernel_size=3, activation='relu')(conv_layer)\n",
    "conv_layer = layers.MaxPool2D(pool_size=(2,2))(conv_layer)\n",
    "\n",
    "conv_x = layers.Flatten(name = 'flattened_features')(conv_layer) #turn image to vector.\n",
    "\n",
    "conv_x = layers.Dense(fc_layer_size, activation='relu', name='first_layer')(conv_x)\n",
    "conv_x = layers.Dense(fc_layer_size, activation='relu', name='second_layer')(conv_x)\n",
    "conv_outputs = layers.Dense(1, activation='sigmoid', name='class')(conv_x)\n",
    "\n",
    "huge_conv_model = keras.Model(inputs=conv_inputs, outputs=conv_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "customAdam = keras.optimizers.Adam(lr=1e-6)\n",
    "huge_conv_model.compile(optimizer=customAdam,  # Optimizer\n",
    "              # Loss function to minimize\n",
    "              loss=\"binary_crossentropy\",\n",
    "              # List of metrics to monitor\n",
    "              metrics=[\"accuracy\",\"mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Fit model on training data\n",
      "Epoch 1/10\n",
      "64/64 [==============================] - 66s 1s/step - loss: 2.0869 - accuracy: 0.5016 - mean_squared_error: 0.4038 - val_loss: 1.2765 - val_accuracy: 0.5289 - val_mean_squared_error: 0.3652\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 67s 1s/step - loss: 1.0677 - accuracy: 0.5347 - mean_squared_error: 0.3325 - val_loss: 1.0719 - val_accuracy: 0.5397 - val_mean_squared_error: 0.3318\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 68s 1s/step - loss: 0.9414 - accuracy: 0.5667 - mean_squared_error: 0.3018 - val_loss: 1.0066 - val_accuracy: 0.5643 - val_mean_squared_error: 0.3165\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 68s 1s/step - loss: 0.8356 - accuracy: 0.6023 - mean_squared_error: 0.2732 - val_loss: 1.0112 - val_accuracy: 0.5653 - val_mean_squared_error: 0.3157\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 68s 1s/step - loss: 0.7666 - accuracy: 0.6221 - mean_squared_error: 0.2548 - val_loss: 0.9128 - val_accuracy: 0.5819 - val_mean_squared_error: 0.2934\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 68s 1s/step - loss: 0.7159 - accuracy: 0.6397 - mean_squared_error: 0.2386 - val_loss: 0.8696 - val_accuracy: 0.5868 - val_mean_squared_error: 0.2830\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 69s 1s/step - loss: 0.6738 - accuracy: 0.6637 - mean_squared_error: 0.2257 - val_loss: 0.8575 - val_accuracy: 0.5849 - val_mean_squared_error: 0.2775\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 68s 1s/step - loss: 0.6441 - accuracy: 0.6841 - mean_squared_error: 0.2146 - val_loss: 0.8446 - val_accuracy: 0.5868 - val_mean_squared_error: 0.2748\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 68s 1s/step - loss: 0.6076 - accuracy: 0.7027 - mean_squared_error: 0.2026 - val_loss: 0.8341 - val_accuracy: 0.5918 - val_mean_squared_error: 0.2702\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 68s 1s/step - loss: 0.5732 - accuracy: 0.7191 - mean_squared_error: 0.1907 - val_loss: 0.8291 - val_accuracy: 0.6065 - val_mean_squared_error: 0.2680\n"
     ]
    }
   ],
   "source": [
    "print('# Fit model on training data')\n",
    "\n",
    "history = huge_conv_model.fit(X_train, \n",
    "                    y_train, #we pass it th labels\n",
    "                    #If the model is taking forever to train, make this bigger\n",
    "                    #If it is taking forever to load for the first epoch, make this smaller\n",
    "                    batch_size=64, \n",
    "                    shuffle = True,\n",
    "                    epochs=10,\n",
    "                    # We pass it validation data to\n",
    "                    # monitor loss and metrics\n",
    "                    # at the end of each epoch\n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de Jason Brownlee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_layer_size = 256\n",
    "img_size = IMG_SIZE\n",
    "\n",
    "conv_inputs = keras.Input(shape=(img_size[1], img_size[0],3), name='ani_image')\n",
    "\n",
    "conv_layer = layers.Conv2D(64, kernel_size=3, activation='relu',\n",
    "                           kernel_initializer='he_uniform')(conv_inputs)\n",
    "conv_layer = layers.MaxPool2D(pool_size=(2,2))(conv_layer)\n",
    "\n",
    "conv_layer = layers.Dropout(0.2)(conv_layer)\n",
    "conv_layer = layers.Conv2D(64, kernel_size=3, activation='relu',\n",
    "                           kernel_initializer='he_uniform')(conv_layer)\n",
    "conv_layer = layers.MaxPool2D(pool_size=(2,2))(conv_layer)\n",
    "\n",
    "conv_layer = layers.Dropout(0.2)(conv_layer)\n",
    "conv_layer = layers.Conv2D(64, kernel_size=3, activation='relu',\n",
    "                           kernel_initializer='he_uniform')(conv_layer)\n",
    "conv_layer = layers.MaxPool2D(pool_size=(2,2))(conv_layer)\n",
    "\n",
    "conv_layer = layers.Dropout(0.2)(conv_layer)\n",
    "conv_x = layers.Flatten(name = 'flattened_features')(conv_layer) #turn image to vector.\n",
    "\n",
    "conv_x = layers.Dense(fc_layer_size, activation='relu', name='first_layer',\n",
    "                      kernel_initializer='he_uniform')(conv_x)\n",
    "conv_x = layers.Dropout(0.5)(conv_x)\n",
    "conv_x = layers.Dense(fc_layer_size, activation='relu', name='second_layer')(conv_x)\n",
    "conv_outputs = layers.Dense(1, activation='sigmoid', name='class')(conv_x)\n",
    "\n",
    "Brownlee_model = keras.Model(inputs=conv_inputs, outputs=conv_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "customAdam = keras.optimizers.Adam(lr=1e-6)\n",
    "Brownlee_model.compile(optimizer=customAdam,  # Optimizer\n",
    "              # Loss function to minimize\n",
    "              loss=\"binary_crossentropy\",\n",
    "              # List of metrics to monitor\n",
    "              metrics=[\"binary_crossentropy\",\"mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Fit model on training data\n",
      "Epoch 1/5\n",
      "64/64 [==============================] - 40s 617ms/step - loss: 148.5111 - binary_crossentropy: 148.5111 - mean_squared_error: 0.4880 - val_loss: 32.5123 - val_binary_crossentropy: 32.5123 - val_mean_squared_error: 0.4938\n",
      "Epoch 2/5\n",
      "64/64 [==============================] - 41s 643ms/step - loss: 128.4026 - binary_crossentropy: 128.4026 - mean_squared_error: 0.5074 - val_loss: 29.5024 - val_binary_crossentropy: 29.5024 - val_mean_squared_error: 0.4945\n",
      "Epoch 3/5\n",
      "64/64 [==============================] - 40s 632ms/step - loss: 120.4583 - binary_crossentropy: 120.4583 - mean_squared_error: 0.4959 - val_loss: 28.5973 - val_binary_crossentropy: 28.5973 - val_mean_squared_error: 0.4930\n",
      "Epoch 4/5\n",
      "64/64 [==============================] - 40s 629ms/step - loss: 112.6544 - binary_crossentropy: 112.6544 - mean_squared_error: 0.4951 - val_loss: 26.3280 - val_binary_crossentropy: 26.3280 - val_mean_squared_error: 0.4864\n",
      "Epoch 5/5\n",
      "64/64 [==============================] - 41s 639ms/step - loss: 106.4453 - binary_crossentropy: 106.4453 - mean_squared_error: 0.5057 - val_loss: 25.7587 - val_binary_crossentropy: 25.7587 - val_mean_squared_error: 0.4885\n"
     ]
    }
   ],
   "source": [
    "print('# Fit model on training data')\n",
    "\n",
    "history = Brownlee_model.fit(X_train, \n",
    "                    y_train, #we pass it th labels\n",
    "                    #If the model is taking forever to train, make this bigger\n",
    "                    #If it is taking forever to load for the first epoch, make this smaller\n",
    "                    batch_size=64, \n",
    "                    shuffle = True,\n",
    "                    epochs=10,                             \n",
    "                    # We pass it validation data to\n",
    "                    # monitor loss and metrics\n",
    "                    # at the end of each epoch\n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "64/64 [==============================] - 121s 2s/step - loss: 5.4601 - binary_crossentropy: 5.4601 - mean_squared_error: 0.3847 - val_loss: 5.3756 - val_binary_crossentropy: 5.3756 - val_mean_squared_error: 0.3758\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 121s 2s/step - loss: 4.8114 - binary_crossentropy: 4.8114 - mean_squared_error: 0.3669 - val_loss: 4.7586 - val_binary_crossentropy: 4.7586 - val_mean_squared_error: 0.3695\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 122s 2s/step - loss: 4.3781 - binary_crossentropy: 4.3781 - mean_squared_error: 0.3536 - val_loss: 4.3236 - val_binary_crossentropy: 4.3236 - val_mean_squared_error: 0.3608\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 120s 2s/step - loss: 4.0675 - binary_crossentropy: 4.0675 - mean_squared_error: 0.3430 - val_loss: 4.0012 - val_binary_crossentropy: 4.0012 - val_mean_squared_error: 0.3480\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 122s 2s/step - loss: 3.8242 - binary_crossentropy: 3.8242 - mean_squared_error: 0.3339 - val_loss: 3.7482 - val_binary_crossentropy: 3.7482 - val_mean_squared_error: 0.3338\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 124s 2s/step - loss: 3.6198 - binary_crossentropy: 3.6198 - mean_squared_error: 0.3238 - val_loss: 3.5484 - val_binary_crossentropy: 3.5484 - val_mean_squared_error: 0.3225\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 124s 2s/step - loss: 3.4456 - binary_crossentropy: 3.4456 - mean_squared_error: 0.3147 - val_loss: 3.3830 - val_binary_crossentropy: 3.3830 - val_mean_squared_error: 0.3138\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 128s 2s/step - loss: 3.2938 - binary_crossentropy: 3.2938 - mean_squared_error: 0.3055 - val_loss: 3.2374 - val_binary_crossentropy: 3.2374 - val_mean_squared_error: 0.3045\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 122s 2s/step - loss: 3.1573 - binary_crossentropy: 3.1573 - mean_squared_error: 0.2972 - val_loss: 3.1119 - val_binary_crossentropy: 3.1119 - val_mean_squared_error: 0.2961\n",
      "Epoch 10/10\n",
      "31/64 [=============>................] - ETA: 49s - loss: 3.2564 - binary_crossentropy: 3.2564 - mean_squared_error: 0.2966"
     ]
    }
   ],
   "source": [
    "# define cnn model\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "\n",
    "img_size = IMG_SIZE\n",
    "\n",
    "model_VGG16 = VGG16(include_top=False, input_shape=(img_size[1], img_size[0],3))\n",
    "for layer in model_VGG16.layers:\n",
    "   layer.trainable = False\n",
    "\n",
    "flat1  = Flatten()(model_VGG16.layers[-1].output)\n",
    "class1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
    "output = Dense(1, activation='sigmoid')(class1)\n",
    "\n",
    "model_VGG16 = Model(inputs=model_VGG16.inputs, outputs=output)\n",
    "\n",
    "customAdam = keras.optimizers.Adam(lr=1e-6)\n",
    "model_VGG16.compile(optimizer=customAdam,  # Optimizer\n",
    "              # Loss function to minimize\n",
    "              loss=\"binary_crossentropy\",\n",
    "              # List of metrics to monitor\n",
    "              metrics=[\"binary_crossentropy\",\"mean_squared_error\"])\n",
    "\n",
    "\n",
    "history = model_VGG16.fit(X_train, \n",
    "                    y_train, #we pass it th labels\n",
    "                    #If the model is taking forever to train, make this bigger\n",
    "                    #If it is taking forever to load for the first epoch, make this smaller\n",
    "                    batch_size = 64, \n",
    "                    shuffle = True,\n",
    "                    epochs=10,                             \n",
    "                    # We pass it validation data to\n",
    "                    # monitor loss and metrics\n",
    "                    # at the end of each epoch\n",
    "                    validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
