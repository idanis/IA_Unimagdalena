{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d4669a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import pandas as pd  \n",
    "import seaborn as sns \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dd44eb",
   "metadata": {},
   "source": [
    "# Cargando los datos de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e2628b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   MedInc      20640 non-null  float64\n",
      " 1   HouseAge    20640 non-null  float64\n",
      " 2   AveRooms    20640 non-null  float64\n",
      " 3   AveBedrms   20640 non-null  float64\n",
      " 4   Population  20640 non-null  float64\n",
      " 5   AveOccup    20640 non-null  float64\n",
      " 6   Latitude    20640 non-null  float64\n",
      " 7   Longitude   20640 non-null  float64\n",
      "dtypes: float64(8)\n",
      "memory usage: 1.3 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Se carga el conjunto de datos California Housing, cuyo objetivo es predecir el valor promedio de una casa \n",
    "#con base en 8 características que tienen que ver con el número de habitaciones promedios de la casa, la antiguedad, \n",
    "#el ingreso promedio de los habitantes de la casa, la ubicación, etc.\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X = pd.DataFrame(data=housing.data, columns=housing.feature_names)\n",
    "print(X.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80f520c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.526 3.585 3.521 ... 0.923 0.847 0.894]\n"
     ]
    }
   ],
   "source": [
    "y = housing.target\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edbabe88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MedInc        0\n",
       "HouseAge      0\n",
       "AveRooms      0\n",
       "AveBedrms     0\n",
       "Population    0\n",
       "AveOccup      0\n",
       "Latitude      0\n",
       "Longitude     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c51758b",
   "metadata": {},
   "source": [
    "# Escalamiento de los datos de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d246f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.539668</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.043512</td>\n",
       "      <td>0.020469</td>\n",
       "      <td>0.008941</td>\n",
       "      <td>0.001499</td>\n",
       "      <td>0.567481</td>\n",
       "      <td>0.211155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.538027</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.038224</td>\n",
       "      <td>0.018929</td>\n",
       "      <td>0.067210</td>\n",
       "      <td>0.001141</td>\n",
       "      <td>0.565356</td>\n",
       "      <td>0.212151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.466028</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052756</td>\n",
       "      <td>0.021940</td>\n",
       "      <td>0.013818</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.564293</td>\n",
       "      <td>0.210159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.354699</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.035241</td>\n",
       "      <td>0.021929</td>\n",
       "      <td>0.015555</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>0.564293</td>\n",
       "      <td>0.209163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.230776</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.038534</td>\n",
       "      <td>0.022166</td>\n",
       "      <td>0.015752</td>\n",
       "      <td>0.001198</td>\n",
       "      <td>0.564293</td>\n",
       "      <td>0.209163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  0.539668  0.784314  0.043512   0.020469    0.008941  0.001499  0.567481   \n",
       "1  0.538027  0.392157  0.038224   0.018929    0.067210  0.001141  0.565356   \n",
       "2  0.466028  1.000000  0.052756   0.021940    0.013818  0.001698  0.564293   \n",
       "3  0.354699  1.000000  0.035241   0.021929    0.015555  0.001493  0.564293   \n",
       "4  0.230776  1.000000  0.038534   0.022166    0.015752  0.001198  0.564293   \n",
       "\n",
       "   Longitude  \n",
       "0   0.211155  \n",
       "1   0.212151  \n",
       "2   0.210159  \n",
       "3   0.209163  \n",
       "4   0.209163  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Escalamiento de los datos de entrada a 1 y 0\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "col_names = housing.feature_names\n",
    "X = MinMaxScaler().fit_transform(X)\n",
    "X = pd.DataFrame(X, columns = col_names )\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2688801e",
   "metadata": {},
   "source": [
    "# Partición de los datos de entrada en entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a210ea3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Partición del conjunto de datos en entrenamiento y prueba. Un 30 por ciento de los datos totales se reserva para prueba\n",
    "Xtrain,Xtest,Ytrain,Ytest = train_test_split(X,y,test_size=0.3,random_state=420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "914e8683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los datos de entrenamiento contienen 14448 registros \n",
      "Los datos de prueba contienen 6192 registros \n"
     ]
    }
   ],
   "source": [
    "print(\"Los datos de entrenamiento contienen %d registros \" % (len(Xtrain)))\n",
    "print(\"Los datos de prueba contienen %d registros \" % (len(Xtest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58e195d",
   "metadata": {},
   "source": [
    "# Perceptron multicapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "219e820f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "model_MPL = MLPRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7487bd3f",
   "metadata": {},
   "source": [
    "#### Prueba 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06b309f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.001, 'hidden_layer_sizes': 50, 'max_iter': 1000}\n"
     ]
    }
   ],
   "source": [
    "#Prueba 1: modelos con una sola capa oculta\n",
    "MPL_parameters = [{'hidden_layer_sizes' : [(10), (20), (30), (50)], 'max_iter':[750, 1000], \n",
    "                   'alpha': [0.001, 0.01, 0.1]}]\n",
    "\n",
    "model_MPL = MLPRegressor()\n",
    "grid_MPL1 = GridSearchCV(model_MPL, MPL_parameters, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_result_MPL1 = grid_MPL1.fit(Xtrain, Ytrain)\n",
    "print(grid_result_MPL1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df9fc444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluacion sobre el conjunto de prueba:  0.3535635227761741\n",
      "The model performance for testing set\n",
      "--------------------------------------\n",
      "MSE is 0.5946120775565983\n",
      "R2 score is 0.7365207586439875\n"
     ]
    }
   ],
   "source": [
    "Ytest_MLP1_predict = grid_result_MPL1.predict(Xtest)\n",
    "mse = mean_squared_error(Ytest, Ytest_MLP1_predict)\n",
    "r2 = r2_score(Ytest, Ytest_MLP1_predict)\n",
    "\n",
    "print(\"The model performance for testing set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('MSE is {}'.format(rmse))\n",
    "print('R2 score is {}'.format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7da98f7",
   "metadata": {},
   "source": [
    "#### Prueba 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4b7742f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.001, 'hidden_layer_sizes': (50, 50), 'max_iter': 1500}\n"
     ]
    }
   ],
   "source": [
    "#prueba 2\n",
    "MPL_parameters = [{'hidden_layer_sizes' : [(50), (25, 25), (50,50)], \n",
    "                   'max_iter':[750, 1000, 1500], \n",
    "                   'alpha': [0.001, 0.01]}]\n",
    "\n",
    "grid_MPL2 = GridSearchCV(model_MPL, MPL_parameters, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_result_MPL2 = grid_MPL2.fit(Xtrain, Ytrain) \n",
    "print(grid_result_MPL2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2009e076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model performance for testing set\n",
      "--------------------------------------\n",
      "RMSE is 0.5623543610855011\n",
      "R2 score is 0.7643328298969219\n"
     ]
    }
   ],
   "source": [
    "Ytest_MLP2_predict = grid_result_MPL2.predict(Xtest)\n",
    "rmse = (np.sqrt(mean_squared_error(Ytest, Ytest_MLP2_predict)))\n",
    "r2 = r2_score(Ytest, Ytest_MLP2_predict)\n",
    "\n",
    "print(\"The model performance for testing set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(rmse))\n",
    "print('R2 score is {}'.format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c4274f",
   "metadata": {},
   "source": [
    "#### Prueba 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6eaf978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best prarams: {'alpha': 0.001, 'hidden_layer_sizes': (75, 75, 50), 'max_iter': 1000}\n"
     ]
    }
   ],
   "source": [
    "#prueba 3\n",
    "MPL_parameters = [{'hidden_layer_sizes' : [(50, 50, 50), (75, 75, 50), (50,50,50,50)], \n",
    "                   'max_iter':[1000, 1500, 2000], \n",
    "                   'alpha': [0.001, 0.01]}]\n",
    "\n",
    "grid_MPL3 = GridSearchCV(model_MPL, MPL_parameters, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_result_MPL3 = grid_MPL3.fit(Xtrain, Ytrain)\n",
    "\n",
    "print('best prarams:', grid_MPL3.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed9da726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model performance for testing set\n",
      "--------------------------------------\n",
      "RMSE is 0.5404329033739587\n",
      "R2 score is 0.7823480728743076\n"
     ]
    }
   ],
   "source": [
    "Ytest_MLP3_predict = grid_result_MPL3.predict(Xtest)\n",
    "rmse = (np.sqrt(mean_squared_error(Ytest, Ytest_MLP3_predict)))\n",
    "r2 = r2_score(Ytest, Ytest_MLP3_predict)\n",
    "\n",
    "print(\"The model performance for testing set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(rmse))\n",
    "print('R2 score is {}'.format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89f4792",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fb3153e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6927a2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los datos de entrenamiento contienen 10836 registros \n",
      "Los datos de prueba contienen 3612 registros \n"
     ]
    }
   ],
   "source": [
    "Xtrain2, Xvalid, Ytrain2, Yvalid = train_test_split(Xtrain, Ytrain, random_state=42)\n",
    "\n",
    "print(\"Los datos de entrenamiento contienen %d registros \" % (len(Xtrain2)))\n",
    "print(\"Los datos de prueba contienen %d registros \" % (len(Xvalid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40b8b1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "339/339 [==============================] - 0s 766us/step - loss: 1.9738 - val_loss: 1.2747\n",
      "Epoch 2/100\n",
      "339/339 [==============================] - 0s 587us/step - loss: 1.2857 - val_loss: 1.2157\n",
      "Epoch 3/100\n",
      "339/339 [==============================] - 0s 540us/step - loss: 1.2213 - val_loss: 1.1541\n",
      "Epoch 4/100\n",
      "339/339 [==============================] - 0s 641us/step - loss: 1.1523 - val_loss: 1.0862\n",
      "Epoch 5/100\n",
      "339/339 [==============================] - 0s 641us/step - loss: 1.0706 - val_loss: 1.0003\n",
      "Epoch 6/100\n",
      "339/339 [==============================] - 0s 591us/step - loss: 0.9709 - val_loss: 0.9030\n",
      "Epoch 7/100\n",
      "339/339 [==============================] - 0s 683us/step - loss: 0.8600 - val_loss: 0.7990\n",
      "Epoch 8/100\n",
      "339/339 [==============================] - 0s 545us/step - loss: 0.7442 - val_loss: 0.7088\n",
      "Epoch 9/100\n",
      "339/339 [==============================] - 0s 640us/step - loss: 0.6598 - val_loss: 0.6411\n",
      "Epoch 10/100\n",
      "339/339 [==============================] - 0s 621us/step - loss: 0.6173 - val_loss: 0.6143\n",
      "Epoch 11/100\n",
      "339/339 [==============================] - 0s 700us/step - loss: 0.5969 - val_loss: 0.5993\n",
      "Epoch 12/100\n",
      "339/339 [==============================] - 0s 634us/step - loss: 0.5862 - val_loss: 0.5903\n",
      "Epoch 13/100\n",
      "339/339 [==============================] - 0s 548us/step - loss: 0.5792 - val_loss: 0.5853\n",
      "Epoch 14/100\n",
      "339/339 [==============================] - 0s 590us/step - loss: 0.5737 - val_loss: 0.5859\n",
      "Epoch 15/100\n",
      "339/339 [==============================] - 0s 584us/step - loss: 0.5683 - val_loss: 0.5765\n",
      "Epoch 16/100\n",
      "339/339 [==============================] - 0s 598us/step - loss: 0.5630 - val_loss: 0.5701\n",
      "Epoch 17/100\n",
      "339/339 [==============================] - 0s 545us/step - loss: 0.5591 - val_loss: 0.5660\n",
      "Epoch 18/100\n",
      "339/339 [==============================] - 0s 545us/step - loss: 0.5545 - val_loss: 0.5608\n",
      "Epoch 19/100\n",
      "339/339 [==============================] - 0s 591us/step - loss: 0.5507 - val_loss: 0.5575\n",
      "Epoch 20/100\n",
      "339/339 [==============================] - 0s 544us/step - loss: 0.5468 - val_loss: 0.5541\n",
      "Epoch 21/100\n",
      "339/339 [==============================] - 0s 590us/step - loss: 0.5425 - val_loss: 0.5487\n",
      "Epoch 22/100\n",
      "339/339 [==============================] - 0s 545us/step - loss: 0.5396 - val_loss: 0.5460\n",
      "Epoch 23/100\n",
      "339/339 [==============================] - 0s 525us/step - loss: 0.5360 - val_loss: 0.5447\n",
      "Epoch 24/100\n",
      "339/339 [==============================] - 0s 591us/step - loss: 0.5325 - val_loss: 0.5452\n",
      "Epoch 25/100\n",
      "339/339 [==============================] - 0s 544us/step - loss: 0.5294 - val_loss: 0.5362\n",
      "Epoch 26/100\n",
      "339/339 [==============================] - 0s 545us/step - loss: 0.5263 - val_loss: 0.5322\n",
      "Epoch 27/100\n",
      "339/339 [==============================] - 0s 652us/step - loss: 0.5231 - val_loss: 0.5305\n",
      "Epoch 28/100\n",
      "339/339 [==============================] - 0s 574us/step - loss: 0.5202 - val_loss: 0.5304\n",
      "Epoch 29/100\n",
      "339/339 [==============================] - 0s 579us/step - loss: 0.5176 - val_loss: 0.5260\n",
      "Epoch 30/100\n",
      "339/339 [==============================] - 0s 556us/step - loss: 0.5158 - val_loss: 0.5244\n",
      "Epoch 31/100\n",
      "339/339 [==============================] - 0s 545us/step - loss: 0.5129 - val_loss: 0.5202\n",
      "Epoch 32/100\n",
      "339/339 [==============================] - 0s 591us/step - loss: 0.5107 - val_loss: 0.5167\n",
      "Epoch 33/100\n",
      "339/339 [==============================] - 0s 544us/step - loss: 0.5087 - val_loss: 0.5168\n",
      "Epoch 34/100\n",
      "339/339 [==============================] - 0s 597us/step - loss: 0.5067 - val_loss: 0.5124\n",
      "Epoch 35/100\n",
      "339/339 [==============================] - 0s 538us/step - loss: 0.5042 - val_loss: 0.5120\n",
      "Epoch 36/100\n",
      "339/339 [==============================] - 0s 544us/step - loss: 0.5024 - val_loss: 0.5086\n",
      "Epoch 37/100\n",
      "339/339 [==============================] - 0s 526us/step - loss: 0.5004 - val_loss: 0.5067\n",
      "Epoch 38/100\n",
      "339/339 [==============================] - 0s 635us/step - loss: 0.4994 - val_loss: 0.5048\n",
      "Epoch 39/100\n",
      "339/339 [==============================] - 0s 545us/step - loss: 0.4974 - val_loss: 0.5041\n",
      "Epoch 40/100\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.499 - 0s 544us/step - loss: 0.4960 - val_loss: 0.5017\n",
      "Epoch 41/100\n",
      "339/339 [==============================] - 0s 565us/step - loss: 0.4942 - val_loss: 0.5040\n",
      "Epoch 42/100\n",
      "339/339 [==============================] - 0s 550us/step - loss: 0.4931 - val_loss: 0.4984\n",
      "Epoch 43/100\n",
      "339/339 [==============================] - 0s 561us/step - loss: 0.4915 - val_loss: 0.4992\n",
      "Epoch 44/100\n",
      "339/339 [==============================] - 0s 492us/step - loss: 0.4899 - val_loss: 0.5019\n",
      "Epoch 45/100\n",
      "339/339 [==============================] - 0s 545us/step - loss: 0.4893 - val_loss: 0.4949\n",
      "Epoch 46/100\n",
      "339/339 [==============================] - 0s 580us/step - loss: 0.4871 - val_loss: 0.4954\n",
      "Epoch 47/100\n",
      "339/339 [==============================] - 0s 570us/step - loss: 0.4865 - val_loss: 0.4996\n",
      "Epoch 48/100\n",
      "339/339 [==============================] - 0s 560us/step - loss: 0.4853 - val_loss: 0.4915\n",
      "Epoch 49/100\n",
      "339/339 [==============================] - 0s 567us/step - loss: 0.4844 - val_loss: 0.4934\n",
      "Epoch 50/100\n",
      "339/339 [==============================] - 0s 543us/step - loss: 0.4832 - val_loss: 0.4887\n",
      "Epoch 51/100\n",
      "339/339 [==============================] - 0s 558us/step - loss: 0.4822 - val_loss: 0.4903\n",
      "Epoch 52/100\n",
      "339/339 [==============================] - 0s 548us/step - loss: 0.4807 - val_loss: 0.4945\n",
      "Epoch 53/100\n",
      "339/339 [==============================] - 0s 562us/step - loss: 0.4800 - val_loss: 0.4868\n",
      "Epoch 54/100\n",
      "339/339 [==============================] - 0s 556us/step - loss: 0.4790 - val_loss: 0.4900\n",
      "Epoch 55/100\n",
      "339/339 [==============================] - 0s 538us/step - loss: 0.4785 - val_loss: 0.4849\n",
      "Epoch 56/100\n",
      "339/339 [==============================] - 0s 578us/step - loss: 0.4780 - val_loss: 0.4834\n",
      "Epoch 57/100\n",
      "339/339 [==============================] - 0s 529us/step - loss: 0.4772 - val_loss: 0.4825\n",
      "Epoch 58/100\n",
      "339/339 [==============================] - 0s 565us/step - loss: 0.4762 - val_loss: 0.4819\n",
      "Epoch 59/100\n",
      "339/339 [==============================] - 0s 526us/step - loss: 0.4753 - val_loss: 0.4826\n",
      "Epoch 60/100\n",
      "339/339 [==============================] - 0s 499us/step - loss: 0.4745 - val_loss: 0.4804\n",
      "Epoch 61/100\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.477 - 0s 545us/step - loss: 0.4741 - val_loss: 0.4797\n",
      "Epoch 62/100\n",
      "339/339 [==============================] - 0s 498us/step - loss: 0.4738 - val_loss: 0.4793\n",
      "Epoch 63/100\n",
      "339/339 [==============================] - 0s 544us/step - loss: 0.4727 - val_loss: 0.4787\n",
      "Epoch 64/100\n",
      "339/339 [==============================] - 0s 610us/step - loss: 0.4724 - val_loss: 0.4779\n",
      "Epoch 65/100\n",
      "339/339 [==============================] - 0s 571us/step - loss: 0.4719 - val_loss: 0.4776\n",
      "Epoch 66/100\n",
      "339/339 [==============================] - 0s 541us/step - loss: 0.4708 - val_loss: 0.4776\n",
      "Epoch 67/100\n",
      "339/339 [==============================] - 0s 536us/step - loss: 0.4707 - val_loss: 0.4769\n",
      "Epoch 68/100\n",
      "339/339 [==============================] - 0s 569us/step - loss: 0.4703 - val_loss: 0.4772\n",
      "Epoch 69/100\n",
      "339/339 [==============================] - 0s 602us/step - loss: 0.4698 - val_loss: 0.4776\n",
      "Epoch 70/100\n",
      "339/339 [==============================] - 0s 620us/step - loss: 0.4692 - val_loss: 0.4758\n",
      "Epoch 71/100\n",
      "339/339 [==============================] - 0s 524us/step - loss: 0.4689 - val_loss: 0.4745\n",
      "Epoch 72/100\n",
      "339/339 [==============================] - 0s 545us/step - loss: 0.4686 - val_loss: 0.4787\n",
      "Epoch 73/100\n",
      "339/339 [==============================] - 0s 576us/step - loss: 0.4678 - val_loss: 0.4749\n",
      "Epoch 74/100\n",
      "339/339 [==============================] - 0s 539us/step - loss: 0.4679 - val_loss: 0.4736\n",
      "Epoch 75/100\n",
      "339/339 [==============================] - 0s 563us/step - loss: 0.4671 - val_loss: 0.4725\n",
      "Epoch 76/100\n",
      "339/339 [==============================] - 0s 550us/step - loss: 0.4669 - val_loss: 0.4727\n",
      "Epoch 77/100\n",
      "339/339 [==============================] - 0s 538us/step - loss: 0.4664 - val_loss: 0.4773\n",
      "Epoch 78/100\n",
      "339/339 [==============================] - 0s 519us/step - loss: 0.4653 - val_loss: 0.4719\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 567us/step - loss: 0.4658 - val_loss: 0.4768\n",
      "Epoch 80/100\n",
      "339/339 [==============================] - 0s 643us/step - loss: 0.4654 - val_loss: 0.4723\n",
      "Epoch 81/100\n",
      "339/339 [==============================] - 0s 683us/step - loss: 0.4654 - val_loss: 0.4710\n",
      "Epoch 82/100\n",
      "339/339 [==============================] - 0s 576us/step - loss: 0.4647 - val_loss: 0.4710\n",
      "Epoch 83/100\n",
      "339/339 [==============================] - 0s 554us/step - loss: 0.4642 - val_loss: 0.4696\n",
      "Epoch 84/100\n",
      "339/339 [==============================] - 0s 715us/step - loss: 0.4633 - val_loss: 0.4703\n",
      "Epoch 85/100\n",
      "339/339 [==============================] - 0s 1ms/step - loss: 0.4637 - val_loss: 0.4686\n",
      "Epoch 86/100\n",
      "339/339 [==============================] - 0s 749us/step - loss: 0.4630 - val_loss: 0.4718\n",
      "Epoch 87/100\n",
      "339/339 [==============================] - 0s 637us/step - loss: 0.4628 - val_loss: 0.4685\n",
      "Epoch 88/100\n",
      "339/339 [==============================] - 0s 644us/step - loss: 0.4622 - val_loss: 0.4683\n",
      "Epoch 89/100\n",
      "339/339 [==============================] - 0s 622us/step - loss: 0.4617 - val_loss: 0.4742\n",
      "Epoch 90/100\n",
      "339/339 [==============================] - 0s 605us/step - loss: 0.4623 - val_loss: 0.4674\n",
      "Epoch 91/100\n",
      "339/339 [==============================] - 0s 616us/step - loss: 0.4619 - val_loss: 0.4685\n",
      "Epoch 92/100\n",
      "339/339 [==============================] - 0s 607us/step - loss: 0.4611 - val_loss: 0.4705\n",
      "Epoch 93/100\n",
      "339/339 [==============================] - 0s 602us/step - loss: 0.4606 - val_loss: 0.4671\n",
      "Epoch 94/100\n",
      "339/339 [==============================] - 0s 561us/step - loss: 0.4603 - val_loss: 0.4667\n",
      "Epoch 95/100\n",
      "339/339 [==============================] - 0s 543us/step - loss: 0.4601 - val_loss: 0.4661\n",
      "Epoch 96/100\n",
      "339/339 [==============================] - 0s 529us/step - loss: 0.4602 - val_loss: 0.4689\n",
      "Epoch 97/100\n",
      "339/339 [==============================] - 0s 538us/step - loss: 0.4597 - val_loss: 0.4656\n",
      "Epoch 98/100\n",
      "339/339 [==============================] - 0s 542us/step - loss: 0.4594 - val_loss: 0.4646\n",
      "Epoch 99/100\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.451 - 0s 531us/step - loss: 0.4591 - val_loss: 0.4647\n",
      "Epoch 100/100\n",
      "339/339 [==============================] - 0s 512us/step - loss: 0.4592 - val_loss: 0.4644\n",
      "194/194 [==============================] - 0s 351us/step - loss: 0.4787\n",
      "MSE con datos de prueba is 0.4786602854728699\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(75, activation=\"relu\", input_shape = Xtrain.shape[1:]),\n",
    "    keras.layers.Dense(75, activation=\"relu\"),\n",
    "    keras.layers.Dense(50, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "history = model.fit(Xtrain2, Ytrain2, epochs=100, validation_data=(Xvalid, Yvalid))\n",
    "\n",
    "mse_test = model.evaluate(Xtest, Ytest)\n",
    "print('MSE con datos de prueba is {}'.format(mse_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a23c07c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "339/339 [==============================] - 0s 783us/step - loss: 1.5745 - val_loss: 1.2853\n",
      "Epoch 2/100\n",
      "339/339 [==============================] - 0s 499us/step - loss: 1.3339 - val_loss: 1.2874\n",
      "Epoch 3/100\n",
      "339/339 [==============================] - 0s 498us/step - loss: 1.3311 - val_loss: 1.2774\n",
      "Epoch 4/100\n",
      "339/339 [==============================] - 0s 480us/step - loss: 1.3268 - val_loss: 1.2739\n",
      "Epoch 5/100\n",
      "339/339 [==============================] - 0s 453us/step - loss: 1.3236 - val_loss: 1.2705\n",
      "Epoch 6/100\n",
      "339/339 [==============================] - 0s 535us/step - loss: 1.3196 - val_loss: 1.2675\n",
      "Epoch 7/100\n",
      "339/339 [==============================] - 0s 473us/step - loss: 1.3146 - val_loss: 1.2628\n",
      "Epoch 8/100\n",
      "339/339 [==============================] - 0s 503us/step - loss: 1.3088 - val_loss: 1.2646\n",
      "Epoch 9/100\n",
      "339/339 [==============================] - 0s 497us/step - loss: 1.3032 - val_loss: 1.2501\n",
      "Epoch 10/100\n",
      "339/339 [==============================] - 0s 480us/step - loss: 1.2946 - val_loss: 1.2436\n",
      "Epoch 11/100\n",
      "339/339 [==============================] - 0s 499us/step - loss: 1.2849 - val_loss: 1.2338\n",
      "Epoch 12/100\n",
      "339/339 [==============================] - 0s 499us/step - loss: 1.2748 - val_loss: 1.2223\n",
      "Epoch 13/100\n",
      "339/339 [==============================] - 0s 480us/step - loss: 1.2621 - val_loss: 1.2098\n",
      "Epoch 14/100\n",
      "339/339 [==============================] - 0s 506us/step - loss: 1.2480 - val_loss: 1.1965\n",
      "Epoch 15/100\n",
      "339/339 [==============================] - 0s 492us/step - loss: 1.2301 - val_loss: 1.1793\n",
      "Epoch 16/100\n",
      "339/339 [==============================] - 0s 480us/step - loss: 1.2092 - val_loss: 1.1567\n",
      "Epoch 17/100\n",
      "339/339 [==============================] - 0s 499us/step - loss: 1.1830 - val_loss: 1.1296\n",
      "Epoch 18/100\n",
      "339/339 [==============================] - 0s 499us/step - loss: 1.1502 - val_loss: 1.0974\n",
      "Epoch 19/100\n",
      "339/339 [==============================] - 0s 480us/step - loss: 1.1102 - val_loss: 1.0556\n",
      "Epoch 20/100\n",
      "339/339 [==============================] - 0s 499us/step - loss: 1.0610 - val_loss: 1.0062\n",
      "Epoch 21/100\n",
      "339/339 [==============================] - 0s 499us/step - loss: 1.0030 - val_loss: 0.9481\n",
      "Epoch 22/100\n",
      "339/339 [==============================] - 0s 480us/step - loss: 0.9349 - val_loss: 0.8817\n",
      "Epoch 23/100\n",
      "339/339 [==============================] - 0s 499us/step - loss: 0.8593 - val_loss: 0.8098\n",
      "Epoch 24/100\n",
      "339/339 [==============================] - 0s 545us/step - loss: 0.7801 - val_loss: 0.7409\n",
      "Epoch 25/100\n",
      "339/339 [==============================] - 0s 480us/step - loss: 0.7047 - val_loss: 0.6730\n",
      "Epoch 26/100\n",
      "339/339 [==============================] - 0s 499us/step - loss: 0.6431 - val_loss: 0.6214\n",
      "Epoch 27/100\n",
      "339/339 [==============================] - 0s 499us/step - loss: 0.5982 - val_loss: 0.5896\n",
      "Epoch 28/100\n",
      "339/339 [==============================] - 0s 480us/step - loss: 0.5714 - val_loss: 0.5726\n",
      "Epoch 29/100\n",
      "339/339 [==============================] - 0s 499us/step - loss: 0.5568 - val_loss: 0.5624\n",
      "Epoch 30/100\n",
      "339/339 [==============================] - 0s 453us/step - loss: 0.5495 - val_loss: 0.5584\n",
      "Epoch 31/100\n",
      "339/339 [==============================] - 0s 480us/step - loss: 0.5441 - val_loss: 0.5517\n",
      "Epoch 32/100\n",
      "339/339 [==============================] - 0s 453us/step - loss: 0.5407 - val_loss: 0.5476\n",
      "Epoch 33/100\n",
      "339/339 [==============================] - 0s 499us/step - loss: 0.5380 - val_loss: 0.5467\n",
      "Epoch 34/100\n",
      "339/339 [==============================] - 0s 480us/step - loss: 0.5355 - val_loss: 0.5426\n",
      "Epoch 35/100\n",
      "339/339 [==============================] - 0s 499us/step - loss: 0.5326 - val_loss: 0.5414\n",
      "Epoch 36/100\n",
      "339/339 [==============================] - 0s 480us/step - loss: 0.5305 - val_loss: 0.5383\n",
      "Epoch 37/100\n",
      "339/339 [==============================] - 0s 499us/step - loss: 0.5283 - val_loss: 0.5362\n",
      "Epoch 38/100\n",
      "339/339 [==============================] - 0s 453us/step - loss: 0.5272 - val_loss: 0.5341\n",
      "Epoch 39/100\n",
      "339/339 [==============================] - 0s 525us/step - loss: 0.5251 - val_loss: 0.5335\n",
      "Epoch 40/100\n",
      "339/339 [==============================] - 0s 480us/step - loss: 0.5236 - val_loss: 0.5306\n",
      "Epoch 41/100\n",
      "339/339 [==============================] - 0s 499us/step - loss: 0.5217 - val_loss: 0.5318\n",
      "Epoch 42/100\n",
      "339/339 [==============================] - 0s 480us/step - loss: 0.5204 - val_loss: 0.5277\n",
      "Epoch 43/100\n",
      "339/339 [==============================] - 0s 434us/step - loss: 0.5188 - val_loss: 0.5269\n",
      "Epoch 44/100\n",
      "339/339 [==============================] - 0s 499us/step - loss: 0.5170 - val_loss: 0.5295\n",
      "Epoch 45/100\n",
      "339/339 [==============================] - 0s 545us/step - loss: 0.5162 - val_loss: 0.5228\n",
      "Epoch 46/100\n",
      "339/339 [==============================] - 0s 479us/step - loss: 0.5139 - val_loss: 0.5223\n",
      "Epoch 47/100\n",
      "339/339 [==============================] - 0s 499us/step - loss: 0.5131 - val_loss: 0.5261\n",
      "Epoch 48/100\n",
      "339/339 [==============================] - 0s 505us/step - loss: 0.5118 - val_loss: 0.5192\n",
      "Epoch 49/100\n",
      "339/339 [==============================] - 0s 474us/step - loss: 0.5107 - val_loss: 0.5201\n",
      "Epoch 50/100\n",
      "339/339 [==============================] - 0s 545us/step - loss: 0.5092 - val_loss: 0.5158\n",
      "Epoch 51/100\n",
      "339/339 [==============================] - 0s 453us/step - loss: 0.5079 - val_loss: 0.5162\n",
      "Epoch 52/100\n",
      "339/339 [==============================] - 0s 480us/step - loss: 0.5062 - val_loss: 0.5207\n",
      "Epoch 53/100\n",
      "339/339 [==============================] - 0s 499us/step - loss: 0.5052 - val_loss: 0.5127\n",
      "Epoch 54/100\n",
      "339/339 [==============================] - 0s 499us/step - loss: 0.5038 - val_loss: 0.5152\n",
      "Epoch 55/100\n",
      "339/339 [==============================] - 0s 545us/step - loss: 0.5030 - val_loss: 0.5101\n",
      "Epoch 56/100\n",
      "339/339 [==============================] - 0s 480us/step - loss: 0.5022 - val_loss: 0.5088\n",
      "Epoch 57/100\n",
      "339/339 [==============================] - 0s 499us/step - loss: 0.5011 - val_loss: 0.5075\n",
      "Epoch 58/100\n",
      "339/339 [==============================] - 0s 499us/step - loss: 0.4997 - val_loss: 0.5062\n",
      "Epoch 59/100\n",
      "339/339 [==============================] - 0s 480us/step - loss: 0.4985 - val_loss: 0.5064\n",
      "Epoch 60/100\n",
      "339/339 [==============================] - 0s 499us/step - loss: 0.4973 - val_loss: 0.5041\n",
      "Epoch 61/100\n",
      "339/339 [==============================] - 0s 499us/step - loss: 0.4966 - val_loss: 0.5031\n",
      "Epoch 62/100\n",
      "339/339 [==============================] - 0s 487us/step - loss: 0.4958 - val_loss: 0.5021\n",
      "Epoch 63/100\n",
      "339/339 [==============================] - 0s 492us/step - loss: 0.4945 - val_loss: 0.5011\n",
      "Epoch 64/100\n",
      "339/339 [==============================] - 0s 499us/step - loss: 0.4938 - val_loss: 0.5002\n",
      "Epoch 65/100\n",
      "339/339 [==============================] - 0s 480us/step - loss: 0.4931 - val_loss: 0.4996\n",
      "Epoch 66/100\n",
      "339/339 [==============================] - 0s 499us/step - loss: 0.4917 - val_loss: 0.4991\n",
      "Epoch 67/100\n",
      "339/339 [==============================] - 0s 545us/step - loss: 0.4914 - val_loss: 0.4979\n",
      "Epoch 68/100\n",
      "339/339 [==============================] - 0s 480us/step - loss: 0.4906 - val_loss: 0.4979\n",
      "Epoch 69/100\n",
      "339/339 [==============================] - 0s 545us/step - loss: 0.4899 - val_loss: 0.4976\n",
      "Epoch 70/100\n",
      "339/339 [==============================] - 0s 499us/step - loss: 0.4890 - val_loss: 0.4963\n",
      "Epoch 71/100\n",
      "339/339 [==============================] - 0s 453us/step - loss: 0.4885 - val_loss: 0.4946\n",
      "Epoch 72/100\n",
      "339/339 [==============================] - 0s 480us/step - loss: 0.4878 - val_loss: 0.4971\n",
      "Epoch 73/100\n",
      "339/339 [==============================] - 0s 499us/step - loss: 0.4867 - val_loss: 0.4942\n",
      "Epoch 74/100\n",
      "339/339 [==============================] - 0s 498us/step - loss: 0.4866 - val_loss: 0.4932\n",
      "Epoch 75/100\n",
      "339/339 [==============================] - 0s 499us/step - loss: 0.4856 - val_loss: 0.4916\n",
      "Epoch 76/100\n",
      "339/339 [==============================] - 0s 525us/step - loss: 0.4852 - val_loss: 0.4914\n",
      "Epoch 77/100\n",
      "339/339 [==============================] - 0s 499us/step - loss: 0.4844 - val_loss: 0.4950\n",
      "Epoch 78/100\n",
      "339/339 [==============================] - 0s 499us/step - loss: 0.4833 - val_loss: 0.4898\n",
      "Epoch 79/100\n",
      "339/339 [==============================] - 0s 526us/step - loss: 0.4834 - val_loss: 0.4934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "339/339 [==============================] - 0s 453us/step - loss: 0.4829 - val_loss: 0.4900\n",
      "Epoch 81/100\n",
      "339/339 [==============================] - 0s 498us/step - loss: 0.4827 - val_loss: 0.4882\n",
      "Epoch 82/100\n",
      "339/339 [==============================] - 0s 480us/step - loss: 0.4818 - val_loss: 0.4879\n",
      "Epoch 83/100\n",
      "339/339 [==============================] - 0s 499us/step - loss: 0.4811 - val_loss: 0.4870\n",
      "Epoch 84/100\n",
      "339/339 [==============================] - 0s 453us/step - loss: 0.4802 - val_loss: 0.4868\n",
      "Epoch 85/100\n",
      "339/339 [==============================] - 0s 480us/step - loss: 0.4804 - val_loss: 0.4856\n",
      "Epoch 86/100\n",
      "339/339 [==============================] - 0s 498us/step - loss: 0.4796 - val_loss: 0.4875\n",
      "Epoch 87/100\n",
      "339/339 [==============================] - 0s 480us/step - loss: 0.4792 - val_loss: 0.4853\n",
      "Epoch 88/100\n",
      "339/339 [==============================] - 0s 471us/step - loss: 0.4784 - val_loss: 0.4849\n",
      "Epoch 89/100\n",
      "339/339 [==============================] - 0s 482us/step - loss: 0.4779 - val_loss: 0.4897\n",
      "Epoch 90/100\n",
      "339/339 [==============================] - 0s 434us/step - loss: 0.4783 - val_loss: 0.4838\n",
      "Epoch 91/100\n",
      "339/339 [==============================] - 0s 453us/step - loss: 0.4777 - val_loss: 0.4840\n",
      "Epoch 92/100\n",
      "339/339 [==============================] - 0s 499us/step - loss: 0.4770 - val_loss: 0.4846\n",
      "Epoch 93/100\n",
      "339/339 [==============================] - 0s 480us/step - loss: 0.4764 - val_loss: 0.4826\n",
      "Epoch 94/100\n",
      "339/339 [==============================] - 0s 523us/step - loss: 0.4760 - val_loss: 0.4821\n",
      "Epoch 95/100\n",
      "339/339 [==============================] - 0s 475us/step - loss: 0.4756 - val_loss: 0.4818\n",
      "Epoch 96/100\n",
      "339/339 [==============================] - 0s 526us/step - loss: 0.4756 - val_loss: 0.4835\n",
      "Epoch 97/100\n",
      "339/339 [==============================] - 0s 483us/step - loss: 0.4751 - val_loss: 0.4808\n",
      "Epoch 98/100\n",
      "339/339 [==============================] - 0s 495us/step - loss: 0.4748 - val_loss: 0.4801\n",
      "Epoch 99/100\n",
      "339/339 [==============================] - 0s 499us/step - loss: 0.4745 - val_loss: 0.4802\n",
      "Epoch 100/100\n",
      "339/339 [==============================] - 0s 480us/step - loss: 0.4743 - val_loss: 0.4796\n",
      "194/194 [==============================] - 0s 321us/step - loss: 0.4929\n",
      "MSE con datos de prueba is 0.4928724765777588\n"
     ]
    }
   ],
   "source": [
    "model2 = keras.models.Sequential([\n",
    "    keras.layers.Dense(80, activation=\"relu\", input_shape = Xtrain.shape[1:]),\n",
    "    keras.layers.Dense(80, activation=\"relu\"),\n",
    "    keras.layers.Dense(80, activation=\"relu\"),\n",
    "    keras.layers.Dense(80, activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model2.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "history = model2.fit(Xtrain2, Ytrain2, epochs=100, validation_data=(Xvalid, Yvalid))\n",
    "\n",
    "mse_test = model2.evaluate(Xtest, Ytest)\n",
    "print('MSE con datos de prueba is {}'.format(mse_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e9fb86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
